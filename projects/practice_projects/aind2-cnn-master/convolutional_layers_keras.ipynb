{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Layers in Keras\n",
    "\n",
    "Convolution with 3x3 window and stride 1:\n",
    "\n",
    "<img src='conv-visualization/images/full-padding-no-strides-transposed.gif'>\n",
    "\n",
    "Image source: http://iamaaditya.github.io/2016/03/one-by-one-convolution/\n",
    "\n",
    "To create a convolutional layer in Keras, we must first import the necessary module:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can create a convolutional layer by using the following format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv2D(filters, kernel_size, strides, padding, activation='relu', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments\n",
    "\n",
    "We must pass the following arguments:\n",
    "\n",
    "- `filters` - The number of filters.\n",
    "- `kernel_size` - Number specifying both the height and width of the (square) convolution window.\n",
    "\n",
    "There are some additional, optional arguments that we might like to tune:\n",
    "\n",
    "- `strides` - The stride of the convolution. If we do not specify anything, strides is set to 1.\n",
    "- `padding` - One of `valid` or `same`. If we do not specify anything, padding is set to `valid`.\n",
    "- `activation` - Typically `relu`. If we do not specify anything, no activation is applied. We are strongly encouraged to add a ReLU activation function to every convolutional layer in your networks.\n",
    "\n",
    "NOTE: It is possible to represent `both kernel_size` and `strides` as either a number or a tuple.\n",
    "\n",
    "\n",
    "\n",
    "When using our convolutional layer as the first layer (appearing after the input layer) in a model, we must provide an additional `input_shape` argument:\n",
    "\n",
    "- `input_shape` - Tuple specifying the height, width, and depth (in that order) of the input.\n",
    "\n",
    "NOTE: Do not include the `input_shape` argument if the convolutional layer is not the first layer in your network.\n",
    "\n",
    "There are many other tunable arguments that we can set to change the behavior of our convolutional layers. To read more about these, we recommend perusing the official [documentation](https://keras.io/layers/convolutional/).\n",
    "\n",
    "### Example 1\n",
    "\n",
    "Say we are constructing a CNN, and out input layer accepts grayscale images that are 200 by 200 pixels (corresponding to a 3D array with height 200, width 200, and depth 1). Then, say we would like the next layer to be a convolutional layer with 16 filters, each with a width and height of 2. When performing the convolution, we  would like the filter to jump two pixels at a time. We also do not want the filter to extend outside of the image boundaries; in other words, we do not want to pad the image with zeros. Then, to construct this convolutional layer, we would use the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv2D(filters=16, kernel_size=2, strides=2, activation='relu', input_shape=(200, 200, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Say we would like the next layer in my CNN to be a convolutional layer that takes the layer constructed in Example 1 as input. Say we would like our new layer to have 32 filters, each with a height and width of 3. When performing the convolution, we would like the filter to jump 1 pixel at a time. We want the convolutional layer to see all regions of the previous layer, and so we do not mind if the filter hangs over the edge of the previous layer when it is performing the convolution. Then, to construct this convolutional layer, we would use the following line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3\n",
    "\n",
    "If we look up code online, it is also common to see convolutional layers in Keras in this format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Conv2D(64, (2,2), activation='relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are 64 filters, each with a size of 2x2, and the layer has a ReLU activation function. The other arguments in the layer use the default values, so the convolution uses a stride of 1, and the padding has been set to `valid`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality\n",
    "\n",
    "Convolution with 3x3 window and stride 1:\n",
    "\n",
    "<img src='conv-visualization/images/convolution-schematic.gif'>\n",
    "\n",
    "Image source: http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution\n",
    "\n",
    "Just as with neural networks, we create a CNN in Keras by first creating a Sequential model.\n",
    "\n",
    "We add layers to the network by using the `.add()` method. Consider the following CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 100, 100, 16)      80        \n",
      "=================================================================\n",
      "Total params: 80\n",
      "Trainable params: 80\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, strides=2, padding='valid', \n",
    "    activation='relu', input_shape=(200, 200, 1)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the dimensions of the convolutional layer line up with our expectations?\n",
    "\n",
    "Feel free to change the values assigned to the arguments (`filters`, `kernel_size`, etc).\n",
    "\n",
    "Take note of how the number of parameters in the convolutional layer changes. This corresponds to the value under `Param #` in the printed output.\n",
    "\n",
    "Also notice how the shape of the convolutional layer changes. This corresponds to the value under `Output Shape` in the printed output. It follows the format: (batch size, height, width, depth).\n",
    "\n",
    "### Formula: Number of Parameters in a Convolutional Layer\n",
    "\n",
    "The number of parameters in a convolutional layer depends on the supplied values of `filters`, `kernel_size`, and `input_shape`. Let us define a few variables:\n",
    "\n",
    "- `K` - the number of filters in the convolutional layer\n",
    "- `F` - the height and width of the convolutional filters\n",
    "- `D_in` - the depth of the previous layer\n",
    "\n",
    "Notice that `K` = `filters`, and `F` = `kernel_size`. Likewise, `D_in` is the last value in the `input_shape` tuple.\n",
    "\n",
    "Since there are `F*F*D_in` weights per filter, and the convolutional layer is composed of `K` filters, the total number of weights in the convolutional layer is `K*F*F*D_in`. Since there is one bias term per filter, the convolutional layer has `K` biases. Thus, the number of parameters in the convolutional layer is given by `K*F*F*D_in + K`.\n",
    "\n",
    "### Formula: Shape of a Convolutional Layer\n",
    "\n",
    "The shape of a convolutional layer depends on the supplied values of `kernel_size`, `input_shape`, `padding` and `stride`. Let us define a few variables:\n",
    "\n",
    "- `K` - the number of filters in the convolutional layer\n",
    "- `F` - the height and width of the convolutional filters\n",
    "- `S` - the stride of the convolution\n",
    "- `H_in` - the height of the previous layer\n",
    "- `W_in` - the width of the previous layer\n",
    "\n",
    "Notice that `K` = `filters`, `F` = `kernel_size`, and `S` = `stride`. Likewise, `H_in` and `W_in` are the first and second value of the `input_shape tuple`, respectively.\n",
    "\n",
    "The depth of the convolutional layer will always equal the number of filters `K`.\n",
    "\n",
    "If `padding` =  `same`, then the spatial dimensions of the convolutional layer are the following:\n",
    "\n",
    "- `height` = `math.ceil(float(H_in) / float(S))`\n",
    "- `width` = `math.ceil(float(W_in) / float(S))`\n",
    "\n",
    "If `padding` = `valid`, then the spatial dimensions of the convolutional layer are the following:\n",
    "\n",
    "- `height` = `math.ceil(float(H_in - F + 1) / float(S))`\n",
    "- `width` = `math.ceil(float(W_in - F + 1) / float(S))`\n",
    "\n",
    "*Note*: Information about the `ceil()` method can be found in the [documentation](https://docs.python.org/3/library/math.html) and some python [tutorials](https://www.tutorialspoint.com/python/number_ceil.htm).\n",
    "\n",
    "### Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=2, padding='same', \n",
    "    activation='relu', input_shape=(128, 128, 3)))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many parameters does this convolutional layer have?\n",
    "\n",
    "    The number of parameters is (32 x 3 x 3 x 3) + 32 = 896, just as shown under `Param #`.\n",
    "    \n",
    "2. What is the depth of the convolutional layer?\n",
    "\n",
    "    The depth of a convolutional layer is always equal to the number of filters, which is 32.\n",
    "    \n",
    "3. What is the width of the convolutional layer?\n",
    "\n",
    "    The width of the convolutional layer is 64, as can be seen from the second element of the `Output Shape` object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
