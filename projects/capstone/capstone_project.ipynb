{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rodrigo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ten classes: `c0`, `c1`, `c2`, `c3`, `c4`, `c5`, `c6`, `c7`, `c8`, `c9`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_list = pd.read_csv('../../../../capstone-project-data/driver_imgs_list.csv')\n",
    "driver_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22419</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_56936.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22420</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_46218.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22421</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_25946.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22422</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_67850.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22423</th>\n",
       "      <td>p081</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_9684.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject classname            img\n",
       "22419    p081        c9  img_56936.jpg\n",
       "22420    p081        c9  img_46218.jpg\n",
       "22421    p081        c9  img_25946.jpg\n",
       "22422    p081        c9  img_67850.jpg\n",
       "22423    p081        c9   img_9684.jpg"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_list.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c0    2489\n",
       "c3    2346\n",
       "c4    2326\n",
       "c6    2325\n",
       "c2    2317\n",
       "c5    2312\n",
       "c1    2267\n",
       "c9    2129\n",
       "c7    2002\n",
       "c8    1911\n",
       "Name: classname, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_list['classname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "p021    1237\n",
       "p022    1233\n",
       "p024    1226\n",
       "p026    1196\n",
       "p016    1078\n",
       "p066    1034\n",
       "p049    1011\n",
       "p051     920\n",
       "p014     876\n",
       "p015     875\n",
       "p035     848\n",
       "p047     835\n",
       "p081     823\n",
       "p012     823\n",
       "p064     820\n",
       "p075     814\n",
       "p061     809\n",
       "p056     794\n",
       "p050     790\n",
       "p052     740\n",
       "p002     725\n",
       "p045     724\n",
       "p039     651\n",
       "p041     605\n",
       "p042     591\n",
       "p072     346\n",
       "Name: subject, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_list['subject'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are 26 different drivers in the training set\n",
    "driver_list['subject'].value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to load datasets.\n",
    "def load_dataset(path, num_classes):\n",
    "    data = load_files(path)\n",
    "    data_files = np.array(data['filenames'])\n",
    "    data_targets = np_utils.to_categorical(np.array(data['target']), num_classes= num_classes)\n",
    "    return data_files, data_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset(path):\n",
    "    data = load_files(path)\n",
    "    data_files = np.array(data['filenames'])\n",
    "    return data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train dataset\n",
    "train_files, train_targets = load_dataset('../../../../capstone-project-data/imgs/train', 10)\n",
    "\n",
    "#valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "#test_files, test_targets = load_dataset('imgs_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a validation set\n",
    "train_files, valid_files, train_targets, valid_targets = train_test_split(train_files, train_targets,\n",
    "                                                                          test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = load_test_dataset('../../../../capstone-project-data/imgs/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../../../../capstone-project-data/imgs/test/test/img_48438.jpg',\n",
       "       '../../../../capstone-project-data/imgs/test/test/img_49454.jpg',\n",
       "       '../../../../capstone-project-data/imgs/test/test/img_94120.jpg',\n",
       "       ...,\n",
       "       '../../../../capstone-project-data/imgs/test/test/img_57211.jpg',\n",
       "       '../../../../capstone-project-data/imgs/test/test/img_58315.jpg',\n",
       "       '../../../../capstone-project-data/imgs/test/test/img_86805.jpg'],\n",
       "      dtype='<U63')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['../../../../capstone-project-data/imgs/train/c4/img_71613.jpg',\n",
       "       '../../../../capstone-project-data/imgs/train/c0/img_67972.jpg',\n",
       "       '../../../../capstone-project-data/imgs/train/c0/img_24317.jpg',\n",
       "       ...,\n",
       "       '../../../../capstone-project-data/imgs/train/c4/img_80041.jpg',\n",
       "       '../../../../capstone-project-data/imgs/train/c2/img_28974.jpg',\n",
       "       '../../../../capstone-project-data/imgs/train/c3/img_71837.jpg'],\n",
       "      dtype='<U62')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../capstone-project-data/imgs/train/c4/img_71613.jpg\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the output of the load_dataset function\n",
    "print(train_files[0])\n",
    "print(train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../capstone-project-data/imgs/train/c0/img_67972.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_files[1])\n",
    "print(train_targets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../capstone-project-data/imgs/train/c0/img_24317.jpg\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_files[2])\n",
    "print(train_targets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of driver actions\n",
    "driver_actions = [item[-3:-1] for item in sorted(glob(\"../../../../capstone-project-data/imgs/train/*/\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17939 training images.\n",
      "There are 4485 validation images.\n",
      "There are 79726 test images.\n",
      "There are 10 possible driver action categories.\n"
     ]
    }
   ],
   "source": [
    "print('There are %d training images.' % len(train_files))\n",
    "print('There are %d validation images.' % len(valid_files))\n",
    "print('There are %d test images.' % len(test_files))\n",
    "print('There are %d possible driver action categories.' % len(driver_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (640, 480, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 640, 480, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_train_files = train_files[:1800]\n",
    "partial_valid_files = valid_files[:440]\n",
    "\n",
    "partial_train_targets = train_targets[:1800]\n",
    "partial_valid_targets = valid_targets[:440]\n",
    "\n",
    "partial_test_files = test_files[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:06<00:00, 265.92it/s]\n",
      "100%|██████████| 440/440 [00:01<00:00, 282.22it/s]\n",
      "100%|██████████| 400/400 [00:01<00:00, 286.38it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(partial_train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(partial_valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(partial_test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 20934/79726 [09:41<27:12, 36.01it/s] "
     ]
    }
   ],
   "source": [
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_tensors shape: (1800, 224, 224, 3)\n",
      "valid_tensors shape: (440, 224, 224, 3)\n",
      "test_tensors shape: (400, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print('train_tensors shape:', train_tensors.shape)\n",
    "print('valid_tensors shape:', valid_tensors.shape)\n",
    "print('test_tensors shape:', test_tensors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               5017700   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 5,029,254\n",
      "Trainable params: 5,029,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n",
    "                        input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 440 samples\n",
      "Epoch 1/10\n",
      "1800/1800 [==============================] - 110s 61ms/step - loss: 2.1822 - acc: 0.2378 - val_loss: 1.6651 - val_acc: 0.4227\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.66512, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 2/10\n",
      "1800/1800 [==============================] - 22s 12ms/step - loss: 1.2538 - acc: 0.5939 - val_loss: 0.9732 - val_acc: 0.6750\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.66512 to 0.97324, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 3/10\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 0.6850 - acc: 0.7889 - val_loss: 0.4933 - val_acc: 0.8614\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.97324 to 0.49329, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 4/10\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 0.3989 - acc: 0.8772 - val_loss: 0.3908 - val_acc: 0.8864\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49329 to 0.39084, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 5/10\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 0.2573 - acc: 0.9250 - val_loss: 0.2498 - val_acc: 0.9227\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.39084 to 0.24979, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 6/10\n",
      "1800/1800 [==============================] - 22s 12ms/step - loss: 0.1909 - acc: 0.9361 - val_loss: 0.2794 - val_acc: 0.9182\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/10\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 0.1391 - acc: 0.9544 - val_loss: 0.1711 - val_acc: 0.9591\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.24979 to 0.17111, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "Epoch 8/10\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 0.1125 - acc: 0.9650 - val_loss: 0.1814 - val_acc: 0.9432\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/10\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 0.0748 - acc: 0.9756 - val_loss: 0.2527 - val_acc: 0.9250\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/10\n",
      "1800/1800 [==============================] - 23s 13ms/step - loss: 0.0710 - acc: 0.9783 - val_loss: 0.1641 - val_acc: 0.9568\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.17111 to 0.16414, saving model to saved_models/weights.best.from_scratch.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7044b0b080>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, partial_train_targets, \n",
    "          validation_data=(valid_tensors, partial_valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_48438.jpg',\n",
       " 'img_49454.jpg',\n",
       " 'img_94120.jpg',\n",
       " 'img_35168.jpg',\n",
       " 'img_39617.jpg',\n",
       " 'img_28296.jpg',\n",
       " 'img_59513.jpg',\n",
       " 'img_59866.jpg',\n",
       " 'img_75812.jpg',\n",
       " 'img_29951.jpg']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files_sub = [item[49:] for item in test_files]\n",
    "test_files_sub[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [model.predict(np.expand_dims(tensor, axis=0))[0] for tensor in test_tensors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.5925621e-09, 9.9976498e-01, 6.3823085e-05, 1.6031933e-08,\n",
       "        1.1273620e-11, 9.6645249e-07, 1.6851294e-04, 8.4690067e-11,\n",
       "        1.6607071e-06, 1.8944355e-08], dtype=float32),\n",
       " array([4.0941010e-03, 4.5869906e-02, 6.1925679e-02, 1.4693019e-04,\n",
       "        2.3065804e-05, 3.2453990e-04, 4.3505676e-02, 4.7804308e-03,\n",
       "        8.0842412e-01, 3.0905535e-02], dtype=float32),\n",
       " array([4.0704061e-04, 2.0452106e-07, 4.7248215e-04, 2.1107606e-07,\n",
       "        1.5778620e-07, 8.0892396e-06, 1.5220662e-05, 9.9774963e-01,\n",
       "        1.3205766e-03, 2.6443478e-05], dtype=float32),\n",
       " array([4.5657125e-05, 3.3312517e-05, 4.6956966e-06, 5.1466901e-02,\n",
       "        7.5861865e-01, 2.9676875e-10, 8.8369444e-02, 1.7200009e-07,\n",
       "        1.0121037e-01, 2.5081026e-04], dtype=float32),\n",
       " array([8.4603246e-04, 9.4048044e-04, 3.9970651e-03, 9.9407780e-06,\n",
       "        4.5081968e-05, 2.1724983e-01, 1.0715737e-04, 1.1313303e-04,\n",
       "        3.8076553e-01, 3.9592576e-01], dtype=float32)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_48438.jpg',\n",
       " 'img_49454.jpg',\n",
       " 'img_94120.jpg',\n",
       " 'img_35168.jpg',\n",
       " 'img_39617.jpg']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_files_sub = [item[49:] for item in test_files]\n",
    "test_files_sub[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_format = np.column_stack((np.asarray(test_files_sub[:400]), \n",
    "                                     np.asarray(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['img_48438.jpg' '1.5925621e-09' '0.999765' '6.3823085e-05'\n",
      "  '1.6031933e-08' '1.127362e-11' '9.664525e-07' '0.00016851294'\n",
      "  '8.469007e-11' '1.6607071e-06' '1.8944355e-08']\n",
      " ['img_49454.jpg' '0.004094101' '0.045869906' '0.06192568' '0.0001469302'\n",
      "  '2.3065804e-05' '0.0003245399' '0.043505676' '0.004780431' '0.8084241'\n",
      "  '0.030905535']\n",
      " ['img_94120.jpg' '0.0004070406' '2.0452106e-07' '0.00047248215'\n",
      "  '2.1107606e-07' '1.577862e-07' '8.08924e-06' '1.5220662e-05'\n",
      "  '0.9977496' '0.0013205766' '2.6443478e-05']\n",
      " ['img_35168.jpg' '4.5657125e-05' '3.3312517e-05' '4.6956966e-06'\n",
      "  '0.0514669' '0.75861865' '2.9676875e-10' '0.088369444' '1.7200009e-07'\n",
      "  '0.10121037' '0.00025081026']\n",
      " ['img_39617.jpg' '0.00084603246' '0.00094048044' '0.003997065'\n",
      "  '9.940778e-06' '4.5081968e-05' '0.21724983' '0.00010715737'\n",
      "  '0.00011313303' '0.38076553' '0.39592576']]\n"
     ]
    }
   ],
   "source": [
    "print(submission_format[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('kaggle_submissions/test_submission.csv', submission_format, delimiter=',', comments='',\n",
    "           newline= '\\n', fmt= '%s', header= 'img, c0, c1, c2, c3, c4, c5, c6, c7 ,c8 ,c9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
